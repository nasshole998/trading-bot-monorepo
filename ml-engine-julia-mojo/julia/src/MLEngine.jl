module MLEngine

# Export symbols you want to be available when the module is used
export start_services, stop_services # More comprehensive start/stop

using gRPC
using ProtoBuf # Needed for Protobuf types
using YAML # For config
using Dates # For timestamps
using CircularArrays # For data buffers
using DataFrames # Example for data handling
using Flux # Example for ML
using CUDA # For GPU acceleration
using NNlib # Neural network primitives
using BSON # For saving/loading models
using HTTP # For health check
using Logging # Standard logging
using JSON # For metadata
using ArgParse # For command-line args
using FileWatching # For config file watching
using SignalInterrupt # For signal handling
using Statistics # For mean, etc.
using Base.Threads # For thread-safe access (ReentrantLock, atomic, Condition)
using ConcurrentUtilities # For Channel (if not using stdlib Channel) or other concurrent tools

# Include generated Protobuf/gRPC files
# These will be placed in MLEngine.jl/src/generated by the build process (protoc)
include("generated/market_data_pb.jl")
include("generated/market_data_grpc.jl")
include("generated/indicator_data_pb.jl")
include("generated/indicator_data_grpc.jl") # Needs client implementation
include("generated/ml_prediction_pb.jl")
include("generated/ml_prediction_grpc.jl")


# Include internal component files
include("config.jl")
include("data_manager.jl")
include("model_definition.jl") # Define model structures
include("model_manager.jl") # Manages loaded models
include("indicator_client.jl") # Client to receive indicator data
include("trainer.jl") # Handles training logic
include("predictor.jl") # Handles prediction logic
include("health_check.jl") # HTTP health check

# Define global or module-level state
# These are the main shared components
const data_manager = DataManager()
const model_manager = ModelManager()
const training_trigger_channel = Channel{Bool}(1) # Channel to signal training task

# --- Core Service Start/Stop ---

# Function to start all services (gRPC server, health check, clients, trainers)
function start_services(config::Config)
    @info "Starting ML Engine Services..."

    # Configure managers
    configure!(data_manager, config.data.max_history_size)
    configure!(model_manager, config.model.artifacts_path)

    # Load initial models based on config
    load_models!(model_manager, config.model.instances) # Pass model configs

    # --- Start gRPC Server (Receives Market Data) ---
    @info "Starting MarketDataService gRPC server on $(config.grpc.listen_address)"
    server = gRPC.listen(config.grpc.listen_address)
    gRPC.add_service(server, market_data.MarketDataService, Dict(
        :StreamMarketData => (ctx, stream) -> handle_stream_market_data(ctx, stream, data_manager)
    ))
     @info "MarketDataService server started."

    # --- Start gRPC Server (Serves Predictions) ---
    # This service might use the same server instance or a different one.
    # Let's use the same server instance for simplicity.
     @info "Registering PredictionService on $(config.grpc.listen_address)"
    gRPC.add_service(server, ml_prediction.PredictionService, Dict(
       :SubscribeToPredictions => (ctx, req) -> handle_subscribe_to_predictions(ctx, req, data_manager, model_manager, config)
   ))
    @info "PredictionService registered."


    # --- Start gRPC Client (Receives Indicator Data) ---
    indicator_client_task = @async start_indicator_client(config.indicator_engine.grpc_address, data_manager, config)
    @info "IndicatorService gRPC client started."


    # --- Start Health Check Server ---
    health_check_task = @async start_health_check_server(config.health_check.listen_address, data_manager, model_manager)
    @info "Health Check server started."

    # --- Start Periodic Training Trigger Task ---
    # This task periodically signals the trainer
    training_trigger_task = @async begin
        @info "Training trigger task started."
        # Initial trigger after a delay to allow some data accumulation
        sleep(config.training.initial_delay_sec)
        put!(training_trigger_channel, true) # Trigger initial training

        while true
            # Wait for the configured training interval
            sleep(config.training.interval_sec)
            @info "Periodic training interval reached. Triggering training."
            put!(training_trigger_channel, true) # Signal the trainer task
        end
    end
     @info "Training trigger task started."


    # --- Start Trainer Task ---
    # This task waits for signals on the training_trigger_channel
    trainer_task = @async begin
        @info "Trainer task started."
        while true
            try
                # Wait for a signal to train
                should_train = take!(training_trigger_channel)
                if !should_train # Use false as a shutdown signal
                    @info "Trainer task received shutdown signal."
                    break
                end
                 @info "Trainer task received train signal. Starting training..."
                # Perform training
                train_models(data_manager, model_manager, config)
                 @info "Training cycle finished."
            catch e
                @error "Error in trainer task: $(e)"
                # Continue running even if one training cycle fails
            end
        end
        @info "Trainer task finished."
    end
     @info "Trainer task started."


    # --- Keep main thread alive (the gRPC.run(server) call blocks) ---
    # To allow graceful shutdown via signals in the main script,
    # the main script needs to wait for a signal and then call stop_services.
    # The gRPC.run(server) call should probably be put in the main script's
    # signal handling loop or in a separate task managed by the main script.

    # For now, we'll just return the tasks and server and rely on the main script
    # to wait for them and call stop_services.

    # The gRPC.run(server) is the main blocking call for the server.
    # Let's run it in an async task here, and the main script will wait on this task.
    grpc_server_task = @async gRPC.run(server)

    @info "ML Engine Services started."

    # Return all tasks and the server handle
    return (grpc_server_task=grpc_server_task, health_check_task=health_check_task,
            indicator_client_task=indicator_client_task, training_trigger_task=training_trigger_task,
            trainer_task=trainer_task, grpc_server=server)
end

# Function to stop all services gracefully
function stop_services(services)
    @info "Stopping ML Engine Services..."

    # 1. Signal the trainer task to stop
    put!(training_trigger_channel, false) # Signal False to stop the trainer task

    # 2. Stop the gRPC server (stops accepting new RPCs, allows current ones to finish)
    @info "Stopping gRPC server..."
    gRPC.stop(services.grpc_server)
    # Note: gRPC.jl might not have an explicit stop for client streams like indicator_client_task.
    # Cancellation is usually handled by the server closing the stream or the client task checking context.

    # 3. Signal health check and other tasks to stop if they have a mechanism
    # The health check task started with HTTP.serve will stop when its task is cancelled
    # or the HTTP server object is explicitly stopped (if HTTP.jl supports that granular control).
    # For simplicity here, we rely on task cancellation when the main process exits or signal propagates.

    # 4. Wait for all tasks to finish (optional but good for clean shutdown confirmation)
    @info "Waiting for service tasks to finish..."
    # try
    #    wait(services.grpc_server_task) # Wait for the main gRPC server task
    #    wait(services.health_check_task) # Wait for health check
    #    wait(services.indicator_client_task) # Wait for indicator client
    #    wait(services.trainer_task) # Wait for trainer
    # catch e
    #     @error "Error while waiting for tasks to finish during shutdown: $(e)"
    # end

    @info "ML Engine Services stopped."
end

# Optional: __init__ function runs when the module is first loaded
# function __init__()
#     @info "MLEngine module initialized"
# end

end # module MLEngine